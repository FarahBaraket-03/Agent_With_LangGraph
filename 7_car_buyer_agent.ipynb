{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f53c11",
   "metadata": {},
   "source": [
    "## Library Descriptions\n",
    "\n",
    "- **patchright**:  \n",
    "    Used for patching and managing updates for certain libraries or configurations.\n",
    "\n",
    "- **lxml**:  \n",
    "    A powerful library for parsing and working with XML and HTML documents, often used in web scraping.\n",
    "\n",
    "- **nest_asyncio**:  \n",
    "    Allows running asynchronous event loops within Jupyter Notebooks, resolving conflicts caused by its built-in event loop.\n",
    "\n",
    "- **playwright**:  \n",
    "    A library for browser automation, used for scraping or testing web applications.\n",
    "\n",
    "- **duckduckgo-search**:  \n",
    "    Provides programmatic access to DuckDuckGo search results for retrieving web-based information.\n",
    "\n",
    "- **gradio**:  \n",
    "    A framework for building user-friendly web-based interfaces, commonly used for showcasing AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import TypedDict, Dict, List ,Any\n",
    "from langgraph.graph import StateGraph, END, START, MessagesState\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage \n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# For scraping\n",
    "from patchright.async_api import async_playwright\n",
    "from lxml import html\n",
    "from abc import ABC, abstractmethod\n",
    "import re\n",
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "#Web Scraping and Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea77cf",
   "metadata": {},
   "source": [
    "### Web Scraping and Interface Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scroll_to_bottom(page, scroll_delay=0.1):\n",
    "    \"\"\"\n",
    "    Scroll to the bottom of the page iteratively, with delays to ensure dynamic content is fully loaded.\n",
    "    \n",
    "    Args:\n",
    "        page: The Playwright page instance.\n",
    "        scroll_delay: Delay in seconds between scrolls to allow content loading.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Scrolling through the page...\")\n",
    "    \n",
    "    scroll_size = 2160\n",
    "\n",
    "    next_scroll = scroll_size\n",
    "    for i in range(3):\n",
    "        # Scroll 500 pixels at a time\n",
    "        await page.evaluate(f\"window.scrollTo(0, {next_scroll})\")\n",
    "\n",
    "        next_scroll += scroll_size\n",
    "\n",
    "        # Wait for content to load\n",
    "        await asyncio.sleep(scroll_delay)\n",
    "        \n",
    "    print(\"Finished scrolling through the page.\")\n",
    "\n",
    "async def block_unnecessary_resources(route):\n",
    "    if route.request.resource_type in [\"image\"]:\n",
    "        await route.abort()\n",
    "    else:\n",
    "        await route.continue_()\n",
    "        \n",
    "class WebsiteInterface(ABC):\n",
    "    def __init__(self):\n",
    "        self.base_url = \"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    async def crawl(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Abstract method to crawl the website and extract listings.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_filters_info(self) -> str:\n",
    "        \"\"\"\n",
    "        Abstract method to return a prompt for the LLM describing the filters and expected output format.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_filters_from_llm_response(self, llm_response: str):\n",
    "        \"\"\"\n",
    "        Abstract method to process the LLM's response and set the URL with appropriate filters.\n",
    "        Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class AutotraderInterface(WebsiteInterface):\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.autotrader.com/cars-for-sale/all-cars\"\n",
    "        # https://www.autotrader.com/cars-for-sale/all-cars/floral-park-ny?endYear=2022&makeCode=BMW&makeCode=FORD&newSearch=true&startYear=2012&zip=11001\n",
    "        \n",
    "    async def crawl(self) -> List[Dict[str, str]]:\n",
    "        listings = []\n",
    "        \n",
    "        url = self.url\n",
    "\n",
    "        playwright = await async_playwright().start()\n",
    "\n",
    "        # Launch browser in headless mode\n",
    "        browser = await playwright.chromium.launch(headless=True,\n",
    "                                                    args=[\n",
    "                                                            \"--no-sandbox\",\n",
    "                                                            \"--disable-setuid-sandbox\",\n",
    "                                                            \"--disable-dev-shm-usage\",\n",
    "                                                            \"--disable-extensions\",\n",
    "                                                            \"--disable-gpu\"\n",
    "                                                    ]\n",
    "                                                    )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            viewport={\"width\": 1920, \"height\": 1080},\n",
    "            # no_viewport=True\n",
    "            locale=\"en-US\",\n",
    "            timezone_id=\"America/New_York\",\n",
    "            # java_script_enabled=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"Opening browser page\")\n",
    "\n",
    "        page = await context.new_page()\n",
    "        \n",
    "        await page.route(\"**/*\", block_unnecessary_resources)\n",
    "\n",
    "        print(\"Loading page\")\n",
    "        \n",
    "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "\n",
    "        print(\"Page partially loaded. Starting to scroll.\")\n",
    "        \n",
    "        # Scroll to the bottom of the page\n",
    "        await scroll_to_bottom(page)\n",
    "        \n",
    "        page_content = await page.content()\n",
    "        \n",
    "        # Parse HTML using lxml\n",
    "        tree = html.fromstring(page_content)\n",
    "\n",
    "        # XPath to select each car listing container\n",
    "        listings_elements = tree.xpath('//div[@data-cmp=\"inventoryListing\"]')\n",
    "\n",
    "        listings = []\n",
    "\n",
    "        for listing in listings_elements:\n",
    "            car_data = {}\n",
    "            # Extract car details\n",
    "            car_data['title'] = listing.xpath('.//h2[@data-cmp=\"subheading\"]/text()')\n",
    "            car_data['mileage'] = listing.xpath('.//div[@data-cmp=\"mileageSpecification\"]/text()')\n",
    "            car_data['price'] = listing.xpath('.//div[@data-cmp=\"firstPrice\"]/text()')\n",
    "            car_data['dealer'] = listing.xpath('.//div[@class=\"text-subdued\"]/text()')\n",
    "            car_data['phone'] = listing.xpath('.//span[@data-cmp=\"phoneNumber\"]/text()')\n",
    "            car_data['url'] = listing.xpath('.//a[@data-cmp=\"link\"]/@href')\n",
    "            car_data['image'] = listing.xpath('.//img[@data-cmp=\"inventoryImage\"]/@src')\n",
    "            \n",
    "            # Clean up extracted data\n",
    "            car_data = {key: (val[0].strip() if val else None) for key, val in car_data.items()}\n",
    "            \n",
    "            car_data['url'] = car_data['url'].split('?')[0]\n",
    "            \n",
    "            # Add domain to the URL. Extract domain from the base URL without the path\n",
    "            car_data['url'] = re.sub(r'^(https?://[^/]+).*$', r'\\1', self.base_url) + car_data['url']\n",
    "            \n",
    "            # Set the ID of the listing as the ID of the WebsiteInterface and the car number from URL\n",
    "            car_data = { \"id\": f\"{self.__class__.__name__}_{car_data['url'].split('/')[-1]}\" } | car_data\n",
    "            \n",
    "            listings.append(car_data)\n",
    "            \n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"Found the following car listings:\")\n",
    "            # Display the extracted data\n",
    "            for car in listings:\n",
    "                print(car)\n",
    "\n",
    "        print(\"Found\", len(listings), \"listings\")\n",
    "\n",
    "        await browser.close()\n",
    "        \n",
    "        return listings\n",
    "    \n",
    "    async def crawl_listing(self, listing_url) -> List[Dict[str, str]]:\n",
    "        listing_info = \"\"\n",
    "        \n",
    "        url = listing_url\n",
    "\n",
    "        playwright = await async_playwright().start()\n",
    "\n",
    "        # Launch browser in headless mode\n",
    "        browser = await playwright.chromium.launch(headless=True,\n",
    "                                                    args=[\n",
    "                                                            \"--no-sandbox\",\n",
    "                                                            \"--disable-setuid-sandbox\",\n",
    "                                                            \"--disable-dev-shm-usage\",\n",
    "                                                            \"--disable-extensions\",\n",
    "                                                            \"--disable-gpu\"\n",
    "                                                    ]\n",
    "                                                    )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "            viewport={\"width\": 1920, \"height\": 1080},\n",
    "            # no_viewport=True\n",
    "            locale=\"en-US\",\n",
    "            timezone_id=\"America/New_York\",\n",
    "            # java_script_enabled=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"Opening browser page\")\n",
    "\n",
    "        page = await context.new_page()\n",
    "        \n",
    "        await page.route(\"**/*\", block_unnecessary_resources)\n",
    "\n",
    "        print(\"Loading page\")\n",
    "        \n",
    "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "\n",
    "        print(\"Page partially loaded. Starting to scroll.\")\n",
    "\n",
    "        # Scroll to the bottom of the page\n",
    "        await scroll_to_bottom(page)\n",
    "\n",
    "        # Get full HTML\n",
    "        page_content = await page.content()\n",
    "\n",
    "        # Parse HTML using lxml to extract all the text\n",
    "        tree = html.fromstring(page_content)\n",
    "        listing_info = tree.xpath(\"//div[contains(@class, 'container') and contains(@class, 'margin-top-5')]/div[contains(@class, 'row')]//text()\")\n",
    "        listing_info = \"\\t\".join(listing_info).strip()\n",
    "\n",
    "        # Seller information should already be included in the listing information\n",
    "        # seller_info = tree.xpath(\"//div[@id='sellerComments']//text()\")\n",
    "        # listing_info = listing_info + seller_info\n",
    "            \n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"Found the following information:\")\n",
    "            # Print the extracted text\n",
    "            print(listing_info)\n",
    "\n",
    "        await browser.close()\n",
    "        \n",
    "        return listing_info\n",
    "    \n",
    "    def get_filters_info(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a prompt for the LLM describing the filters and expected output format.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        You are a helpful assistant that translates user requirements into a URL with query parameters.\n",
    "\n",
    "        The base URL is: {self.base_url}\n",
    "        Filters:\n",
    "        - zip: User's zip code (integer).\n",
    "        - searchRadius: Search radius in miles (integer, e.g., 75, 100, 200).\n",
    "        - startYear: Minimum year of the car (integer).\n",
    "        - endYear: Maximum year of the car (integer).\n",
    "        - makeCode: Car manufacturer code (string, can appear multiple times, e.g., \"BMW\", \"FORD\").\n",
    "        - listingType: Type of listing (one of \"NEW\", \"USED\", \"CERTIFIED\", \"3P_CERT\").\n",
    "        - mileage: Maximum mileage of the car (integer).\n",
    "        - driveGroup: Type of drive (one of \"AWD4WD\", \"FWD\", \"RWD\").\n",
    "        - extColorSimple: External color of the car (e.g., \"BLACK\", \"WHITE\", \"RED\", \"GRAY\").\n",
    "        - intColorSimple: Internal color of the car (e.g., \"BEIGE\", \"BLACK\", \"BLUE\").\n",
    "        - mpgRange: Fuel efficiency in miles per gallon (e.g., \"30-MPG\").\n",
    "        - fuelTypeGroup: Type of fuel (one of \"GSL\", \"DSL\", \"HYB\", \"ELE\", \"PIH\").\n",
    "        - bodyStyleSubtypeCode: Type of body style (e.g., \"FULLSIZE_CREW\", \"COMPACT_EXTEND\").\n",
    "        - truckBedLength: Truck bed length (e.g., \"SHORT\", \"EXTRA SHORT\", \"UNSPECIFIED\").\n",
    "        - vehicleStyleCode: Vehicle style (e.g., \"CONVERT\", \"WAGON\", \"HATCH\", \"SUVCROSS\").\n",
    "        - dealType: Type of deal (e.g., \"goodprice\", \"greatprice\").\n",
    "        - doorCode: Number of doors (e.g., \"2\", \"3\", \"4\").\n",
    "        - engineDisplacement: Engine size range in liters (e.g., \"1.0-1.9\", \"2.0-2.9\").\n",
    "        - featureCode: Specific features of the car (e.g., \"1062\" for heated seats, \"1327\" for navigation).\n",
    "        - transmissionCode: Transmission type (e.g., \"AUT\" for automatic, \"MAN\" for manual).\n",
    "        - vehicleHistoryType: Vehicle history (e.g., \"NO_ACCIDENTS\", \"ONE_OWNER\", \"CLEAN_TITLE\").\n",
    "        - newSearch: Boolean to indicate a new search (e.g., \"true\").\n",
    "        - sortBy: Sorting option for the results (optional). \n",
    "            Options:\n",
    "            - \"relevance\" (default): Sort by relevance.\n",
    "            - \"derivedpriceASC\": Sort by price, lowest to highest.\n",
    "            - \"derivedpriceDESC\": Sort by price, highest to lowest.\n",
    "            - \"distanceASC\": Sort by distance, closest to farthest.\n",
    "            - \"datelistedASC\": Sort by date, oldest first.\n",
    "            - \"datelistedDESC\": Sort by date, newest first.\n",
    "            - \"mileageASC\": Sort by mileage, lowest to highest.\n",
    "            - \"mileageDESC\": Sort by mileage, highest to lowest.\n",
    "            - \"yearASC\": Sort by year, oldest to newest.\n",
    "            - \"yearDESC\": Sort by year, newest to oldest.\n",
    "        \n",
    "        Special filters:\n",
    "        - price: Price is embedded in the path of the URL, e.g., \"/cars-over-45000\" or \"/cars-between-10000-and-20000\".\n",
    "\n",
    "        Example Output:\n",
    "        A complete URL with query parameters, e.g.,:\n",
    "        \"{self.base_url}/cars-between-10000-and-20000?zip=10001&startYear=2010&endYear=2020&makeCode=BMW&makeCode=FORD&listingType=USED&mileage=50000&fuelTypeGroup=GSL&intColorSimple=BLACK&vehicleHistoryType=NO_ACCIDENTS\"\n",
    "\n",
    "        Based on the user's needs, format the response as only the complete URL (no extra explanations). The URL is an example, don't include filters if they are not needed by the user.\n",
    "        \"\"\"\n",
    "        \n",
    "    def set_filters_from_llm_response(self, llm_response: str):\n",
    "        \"\"\"\n",
    "        Process the LLM's response and set the URL with the provided parameters.\n",
    "        \"\"\"\n",
    "        # Validate and set the URL from LLM's response\n",
    "        if llm_response.startswith(self.base_url):\n",
    "            self.url = llm_response.strip()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid URL format provided by LLM response: \" + llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82161243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "GPT = ChatOllama(model=\"mistral\", temperature=0, max_retries=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9397fd",
   "metadata": {},
   "source": [
    "### Define the State Class\n",
    "\n",
    "This cell defines the `State` class, which inherits from `MessagesState`, to represent the current state of the car-buying process. It includes:\n",
    "\n",
    "- **user_needs**: Stores the user s requirements for the car (e.g., budget, features).\n",
    "- **web_interfaces**: A list of web scraper interfaces (e.g., AutoTrader) to fetch car listings.\n",
    "- **listings**: A collection of car listings retrieved from the web platforms.\n",
    "- **selected_listing**: The specific car listing chosen by the user for further exploration.\n",
    "- **additional_info**: Additional information about the selected car (e.g., common issues, reliability).\n",
    "- **next_node**: The next action or state transition in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4403158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    user_needs: Dict[str, Any] = {}\n",
    "    web_interfaces: List[WebsiteInterface] = []\n",
    "    listings: List[Dict[str, Any]] = []\n",
    "    selected_listing: Dict[str, Any] = {}\n",
    "    additional_info: Dict[str, Any] = {}\n",
    "    next_node: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input(*args, **kwargs):\n",
    "    \"\"\"Get user input.\"\"\"\n",
    "    return input(*args, **kwargs)\n",
    "\n",
    "def show_assistant_output(*args, **kwargs):\n",
    "    \"\"\"Show the output of the LLM.\"\"\"\n",
    "    print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class NextStep(Enum):\n",
    "    ASK_USER_NEEDS = \"ask_user_needs\"\n",
    "    BUILD_FILTERS = \"build_filters\"\n",
    "    IRRELEVANT = \"irrelevant\"\n",
    "\n",
    "class UserNeeds(BaseModel):\n",
    "    user_needs: str\n",
    "    next_step: NextStep\n",
    "\n",
    "USER_NEEDS_GPT = ChatOllama(model=\"mistral\", response_format=UserNeeds)\n",
    "\n",
    "def ask_user_needs(state: State) -> State:\n",
    "    \"\"\"Ask user initial questions to define their needs for the car.\"\"\"\n",
    "    messages = state.get(\"messages\", [])    \n",
    "    if len(messages) == 0:\n",
    "        system_message = \"You are a car buying assistant. Your goal is to help the user find a car that meets their needs. Start by introducing yourself and asking about their requirements, such as intended usage (e.g., commuting, family trips), budget, size preferences, and any specific constraints or features they value. Use their responses to guide them toward the best options.\"\n",
    "    else:\n",
    "        system_message = \"Ask the user for any additional information that can help narrow down the search. If he asked any questions before, answer them before asking for more information. When answering, make sure to provide clear and concise information, with relevant examples.\"\n",
    "        \n",
    "    existing_needs = state.get(\"user_needs\", \"\")\n",
    "    if existing_needs:\n",
    "        system_message += f\" Here's what we know about the needs of the user so far:\\n\\n{existing_needs}\"\n",
    "\n",
    "    messages.append(SystemMessage(content=system_message))\n",
    "\n",
    "    # Get message from the LLM\n",
    "    response = GPT.invoke(messages).content\n",
    "    messages += [AIMessage(response)]\n",
    "    show_assistant_output(f\"\\033[92m{messages[-1].content}\\033[0m\", flush=True)\n",
    "    \n",
    "    messages += [HumanMessage(get_user_input(response))]\n",
    "    print(f\"\\033[94m{messages[-1].content}\\033[0m\", flush=True)\n",
    "    \n",
    "    summarization_messages = messages.copy()\n",
    "    \n",
    "    summarization_messages += [\n",
    "        SystemMessage(\n",
    "            \"Summarize the user's car-buying needs in clear and concise bullet points based on their input and any prior knowledge.\\n\"\n",
    "            \"Provide the next step, such as asking for more details or answer questions under ask_user_needs or going forward to build_filter:\\n\"\n",
    "            \"- Use 'ask_user_needs' if you need more information or if the user asked a question.\\n\"\n",
    "            \"- Use 'build_filters' if you have enough details to search for cars online.\\n\"\n",
    "            \"If the user's query is irrelevant to the matter at hand (buying a car), respond 'irrelevant'.\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Get the structured response directly as a Pydantic model\n",
    "    try:\n",
    "        response_model = USER_NEEDS_GPT.invoke(summarization_messages)\n",
    "        response = response_model.content  # This should be a UserNeeds instance\n",
    "    except Exception as e:\n",
    "        # Fallback in case of error\n",
    "        print(f\"Error getting structured response: {e}\")\n",
    "        response = UserNeeds(\n",
    "            user_needs=\"Could not parse user needs from conversation\",\n",
    "            next_step=NextStep.ASK_USER_NEEDS\n",
    "        )\n",
    "\n",
    "    state[\"user_needs\"] = response.user_needs\n",
    "    \n",
    "    messages += [AIMessage(\"I have summarized your car-buying needs as follows:\\n\" + state[\"user_needs\"])]\n",
    "    \n",
    "    show_assistant_output(f\"\\033[92m{messages[-1].content}\\033[0m\")\n",
    "    \n",
    "    state[\"next_node\"] = response.next_step.value  # Get the string value from the Enum\n",
    "        \n",
    "    print(f\"\\nNext node: {state['next_node']}\", flush=True)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filters(state: State) -> State:\n",
    "    \"\"\"Build and refine search filters based on user needs.\"\"\"\n",
    "\n",
    "    show_assistant_output(\"Building filters based on user needs...\")\n",
    "    \n",
    "    for interface in state[\"web_interfaces\"]:\n",
    "        filters_info = interface.get_filters_info()\n",
    "        \n",
    "        # TODO: Check if this website is useful to the user based on the filters\n",
    "        # If not continue to the next interface\n",
    "        \n",
    "        # If the website is useful, use LLM to setup the filters based on user needs\n",
    "        \n",
    "        # Define system instructions with filters information\n",
    "        system_message = SystemMessage(filters_info + \"\\n\\n\" + \"User needs:\\n\" + state[\"user_needs\"])\n",
    "\n",
    "        # Use the LLM to process the user's needs and set the filters\n",
    "        try:\n",
    "            result = GPT.invoke([system_message])\n",
    "            llm_response = result.content.strip()\n",
    "\n",
    "            # Validate and set the filters for the interface\n",
    "            interface.set_filters_from_llm_response(llm_response)\n",
    "            show_assistant_output(f\"\\nSuccessfully set filters for: {interface.__class__.__name__}\")\n",
    "            show_assistant_output(f\"Updated URL: {interface.url}\")\n",
    "        except ValueError as e:\n",
    "            show_assistant_output(f\"Failed to set filters for {interface.base_url}: {e}\")\n",
    "        except Exception as e:\n",
    "            show_assistant_output(f\"An error occurred while processing filters for {interface.base_url}: {e}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78cd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_listings_from_sources(web_interfaces: List[WebsiteInterface]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Simulate retrieval of car listings from Autotrader.com based on filters.\n",
    "    \n",
    "    Args:\n",
    "        filters (dict): Dictionary containing search filters (e.g., budget, fuel type).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries, each representing a car listing.\n",
    "    \"\"\"\n",
    "    listings = []\n",
    "    for interface in web_interfaces:\n",
    "        listings += await interface.crawl()\n",
    "        \n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "\n",
    "class UserResponse(BaseModel):\n",
    "    action: Literal['select_listing', 'refine_search', 'end_conversation']\n",
    "    listing_id: Optional[str]\n",
    "\n",
    "CLASSIFIER_GPT = ChatOllama(model=\"mistral\", response_format=UserResponse)\n",
    "\n",
    "def search_listings(state: State) -> State:\n",
    "    \"\"\"Search for cars on LaCentrale and mobile.de based on filters.\"\"\"\n",
    "    \"\"\"Display the first listings for the user to view.\"\"\"\n",
    "    \"\"\"Synchronous wrapper for search_listings.\"\"\"\n",
    "\n",
    "    state[\"messages\"] += [SystemMessage(\"Searching for listings based on user needs, this may take time...\")]\n",
    "    show_assistant_output(state[\"messages\"][-1].content)\n",
    "\n",
    "    async def _search_listings():\n",
    "        return await fetch_listings_from_sources(state[\"web_interfaces\"])\n",
    "    \n",
    "    listings = asyncio.run(_search_listings())\n",
    "    state[\"listings\"] = listings\n",
    "    \n",
    "    show_assistant_output(f\"Successfully fetched {len(listings)} listings from the sources.\")\n",
    "    \n",
    "    AI_message = \"\"\n",
    "    \n",
    "    # Display the first few listings for the user to view\n",
    "    AI_message += \"Here are recent listings that match your requirements:\\n\"\n",
    "    for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "        AI_message += f\"{i}.\\n\"\n",
    "        for key, value in listing.items():\n",
    "            formatted_key = key.replace(\"_\", \" \").capitalize()\n",
    "            if formatted_key == \"Image\" and value:\n",
    "                AI_message += f\"   {formatted_key}: ![Example Image]({value})\\n\"\n",
    "            else:\n",
    "                AI_message += f\"   {formatted_key}: {value}\\n\"\n",
    "        AI_message += \"\\n\"  # Add an extra line for readability\n",
    "    \n",
    "    user_prompt = \"Would you like to view more details about a specific listing, or refine your search (Write END to finish this conversation) ?\"\n",
    "    AI_message += user_prompt\n",
    "        \n",
    "    state[\"messages\"].append(AIMessage(AI_message))\n",
    "    show_assistant_output(f\"\\033[92m{state['messages'][-1].content}\\033[0m\")\n",
    "    state[\"messages\"].append(HumanMessage(get_user_input(user_prompt)))\n",
    "    print(f\"\\033[94m{state['messages'][-1].content}\\033[0m\")\n",
    "       \n",
    "    response = json.loads(CLASSIFIER_GPT.invoke(state[\"messages\"]).content)\n",
    "\n",
    "    if response[\"action\"] == \"select_listing\":\n",
    "        state[\"next_node\"] = \"fetch_additional_info\"\n",
    "        selected_listing_id = response[\"listing_id\"]\n",
    "        for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "            if selected_listing_id in listing[\"id\"]:\n",
    "                state[\"selected_listing\"] = listing\n",
    "                break\n",
    "    elif response[\"action\"] == \"refine_search\":\n",
    "        state[\"next_node\"] = \"ask_user_needs\"\n",
    "    else:\n",
    "        state[\"next_node\"] = END\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "duckduckgo_search = DuckDuckGoSearchResults(max_results=3)\n",
    "\n",
    "def fetch_additional_info(state: State) -> State:\n",
    "    \"\"\"Fetch more details about the selected car listing.\"\"\"\n",
    "    listing = state[\"selected_listing\"]\n",
    "\n",
    "    # Crawl the car listing page to get more details about the car for sale and the seller\n",
    "\n",
    "    async def _crawl_car_listing():\n",
    "        for interface in state[\"web_interfaces\"]:\n",
    "            if listing[\"id\"].split(\"_\")[0].lower() in interface.__class__.__name__.lower():\n",
    "                return await interface.crawl_listing(listing[\"url\"])\n",
    "    \n",
    "    info_car_for_sale = asyncio.run(_crawl_car_listing())\n",
    "\n",
    "    # Call the LLM to summarize the information about the car for sale into a concise paragraph\n",
    "    prompt = SystemMessage(\n",
    "        f\"Summarize all the relevant information about the selected car for sale into a paragraph: {listing['title']}\\n\\n\"\n",
    "        f\"Here is the raw information about the car for sale:\\n\\n{info_car_for_sale}\"\n",
    "        f\"Format the summary clearly and concisely, with line breaks between sections.\"\n",
    "    )\n",
    "\n",
    "    car_info_summary = GPT.invoke([prompt]).content\n",
    "\n",
    "    show_assistant_output(\"\\033[92mHere are more details about the car for sale:\\n\\033[0m\", flush=True)\n",
    "\n",
    "    show_assistant_output(\"\\033[92m\" + car_info_summary + \"\\n\\n\\033[0m\", flush=True)\n",
    "\n",
    "    state[\"messages\"] += [prompt, AIMessage(car_info_summary)]\n",
    "\n",
    "    # Search for common issues and reliability of the car on DuckDuckGo\n",
    "    car_name = listing[\"title\"]\n",
    "\n",
    "    queries = [f\"{car_name} common issues\", f\"{car_name} problem\", f\"{car_name} reliability\"]\n",
    "    context = \"\"\n",
    "    for query in queries:\n",
    "        search_results = duckduckgo_search.invoke(query)\n",
    "        formatted_results = f\"QUERY: {query}\\n\\n{search_results}\\n-------------------\\n\"\n",
    "        context += formatted_results\n",
    "\n",
    "    prompt = SystemMessage(\n",
    "        f\"Provide additional information about this car: {listing['title']}, \"\n",
    "        f\"including engine specifications, common issues with this model, and market value.\"\n",
    "        f\"Here is additioanl context to help you provide the information:\\n\\n{context}\"\n",
    "        f\"Here are the user needs, give some insights about the car based on the user needs:\\n\\n{state['user_needs']}\"\n",
    "    )\n",
    "    \n",
    "    result = GPT.invoke([prompt])\n",
    "    \n",
    "    listing[\"additional_info\"] = result.content\n",
    "    \n",
    "    show_assistant_output(f\"\\033[92mHere is additional information about the model in general, coming from Internet:\\n{listing['additional_info']}\\n\\033[0m\")\n",
    "    \n",
    "    user_prompt = \"Would you like to view more details about another listing, or refine your search (Write END to finish this conversation) ?\"\n",
    "    state[\"messages\"] += [SystemMessage(user_prompt)]\n",
    "    state[\"messages\"] += [HumanMessage(get_user_input(user_prompt))]\n",
    "    print(f\"\\033[94m{state['messages'][-1].content}\\033[0m\", flush=True)\n",
    "    \n",
    "    response = json.loads(CLASSIFIER_GPT.invoke(state[\"messages\"]).content)\n",
    "\n",
    "    if response[\"action\"] == \"select_listing\":\n",
    "        state[\"next_node\"] = \"fetch_additional_info\"\n",
    "        selected_listing_id = response[\"listing_id\"]\n",
    "        for i, listing in enumerate(state[\"listings\"][:5], 1):\n",
    "            if selected_listing_id in listing[\"id\"]:\n",
    "                state[\"selected_listing\"] = listing\n",
    "                break\n",
    "    elif response[\"action\"] == \"refine_search\":\n",
    "        state[\"next_node\"] = \"ask_user_needs\"\n",
    "    else:\n",
    "        state[\"next_node\"] = END\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37360a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes in the graph\n",
    "workflow.add_node(\"ask_user_needs\", ask_user_needs)\n",
    "workflow.add_node(\"build_filters\", build_filters)\n",
    "workflow.add_node(\"search_listings\", search_listings)\n",
    "workflow.add_node(\"fetch_additional_info\", fetch_additional_info)\n",
    "workflow.add_node(\"irrelevant\", lambda state: state)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_conditional_edges(\"ask_user_needs\", lambda state: state[\"next_node\"], [\"build_filters\", \"ask_user_needs\", \"irrelevant\"])\n",
    "workflow.add_edge(\"build_filters\", \"search_listings\")\n",
    "workflow.add_conditional_edges(\"search_listings\", lambda state: state[\"next_node\"], [\"fetch_additional_info\", \"ask_user_needs\", END])\n",
    "workflow.add_edge(\"irrelevant\", END)\n",
    "\n",
    "# Set the entry and exit points\n",
    "workflow.set_entry_point(\"ask_user_needs\")\n",
    "workflow.add_conditional_edges(\"fetch_additional_info\", lambda state: state[\"next_node\"], [\"ask_user_needs\", \"fetch_additional_info\", END])\n",
    "\n",
    "\n",
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43253ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e28bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_car_buyer_agent():\n",
    "    \"\"\"Run the car-buying assistant with LangGraph.\"\"\"\n",
    "        \n",
    "    messages = []\n",
    "    \n",
    "    initial_state = State(\n",
    "        user_needs={}, \n",
    "        web_interfaces=[AutotraderInterface()], \n",
    "        listings=[],\n",
    "        selected_listing={}, \n",
    "        additional_info={},\n",
    "        next_node=\"\",\n",
    "        messages=messages\n",
    "    )\n",
    "    result = app.invoke(initial_state)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GRADIO = True\n",
    "\n",
    "if not USE_GRADIO:\n",
    "    def get_user_input(*args, **kwargs):\n",
    "        \"\"\"Get user input.\"\"\"\n",
    "        return input(*args, **kwargs)\n",
    "\n",
    "    def show_assistant_output(*args, **kwargs):\n",
    "        \"\"\"Show the output of the LLM.\"\"\"\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "    # Execute the agent\n",
    "    car_buyer_result = run_car_buyer_agent()\n",
    "\n",
    "    # Print result for debugging purposes\n",
    "    print(\"Car Buyer Result:\", car_buyer_result)\n",
    "\n",
    "    # Display summary of the final recommendation\n",
    "    if \"selected_listing\" in car_buyer_result:\n",
    "        listing = car_buyer_result[\"selected_listing\"]\n",
    "        print(f\"\\nFinal Recommendation:\\n{listing['title']} - {listing['price']} - {listing['mileage']} km\")\n",
    "        print(\"Additional Information:\")\n",
    "        for key, value in car_buyer_result[\"additional_info\"].items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"No car listing selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import gradio as gr\n",
    "from gradio import ChatMessage\n",
    "import time\n",
    "import re\n",
    "\n",
    "waiting_for_input = False # Flag to indicate if the agent is waiting for user input\n",
    "\n",
    "class InputQueue:\n",
    "    \"\"\"A custom input queue that mimics stdin behavior.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.queue = queue.Queue()\n",
    "\n",
    "    def readline(self):\n",
    "        \"\"\"Mimic the readline behavior of stdin.\"\"\"\n",
    "        try:\n",
    "            r = self.queue.get(block=True)  # Wait until input is available\n",
    "            return r\n",
    "        except queue.Empty:\n",
    "            return \"\"\n",
    "\n",
    "    def write(self, message):\n",
    "        \"\"\"Handle writes if needed (for debugging).\"\"\"\n",
    "        pass\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"No-op for compatibility.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def put(self, message):\n",
    "        \"\"\"Put a message into the queue.\"\"\"\n",
    "        self.queue.put(message)\n",
    "\n",
    "# A thread-safe queue for communication\n",
    "output_queue = queue.Queue()\n",
    "# Replace sys.stdin with the custom InputQueue\n",
    "input_queue = queue.Queue()\n",
    "\n",
    "def get_user_input(*args, **kwargs):\n",
    "    \"\"\"Get user input.\"\"\"\n",
    "    global waiting_for_input\n",
    "    print(\"Waiting for user input...\")\n",
    "    waiting_for_input = True\n",
    "    r = input_queue.get()\n",
    "    waiting_for_input = False\n",
    "    print(f\"Received user input\")\n",
    "    return r\n",
    "\n",
    "def show_assistant_output(*args, **kwargs):\n",
    "    \"\"\"Show the output of the LLM.\"\"\"\n",
    "    \n",
    "    result = \" \".join(args) + kwargs.get(\"end\", \"\\n\")\n",
    "    \n",
    "    # Replace any Color Codes with Regex\n",
    "    result = re.sub(r'\\033\\[\\d+m', '', result)\n",
    "    # result = result.replace(\"\\033[92m\", \"\").replace(\"\\033[0m\", \"\").replace(\"\\033[94m\", \"\")\n",
    "    \n",
    "    output_queue.put(result)\n",
    "\n",
    "# Gradio UI Functionality\n",
    "def interact_with_agent(user_message, history, discard_user_input=False):\n",
    "    \"\"\"Send user message to the bot and handle the response.\"\"\"\n",
    "    \n",
    "    global waiting_for_input\n",
    "    \n",
    "    if not discard_user_input:\n",
    "        input_queue.put(user_message + \"\\n\")  # Send user input to LangGraph\n",
    "        \n",
    "    partial_message = \"\"\n",
    "\n",
    "    # Fetch and yield bot responses incrementally\n",
    "    while True:\n",
    "        try:\n",
    "            message = output_queue.get(timeout=0.1)  # Wait for bot output\n",
    "            if message:\n",
    "                    \n",
    "                partial_message += message\n",
    "                yield partial_message\n",
    "        except queue.Empty:\n",
    "            is_end = waiting_for_input\n",
    "            if is_end:\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "def get_initial_message():\n",
    "    \"\"\"Run the agent and capture the initial message.\"\"\"\n",
    "    # Simulate an initial empty input to get the initial message\n",
    "    initial_message = \"\"\n",
    "    \n",
    "    for message in interact_with_agent(\"\", [], True):  # Consume the generator to get the full initial message\n",
    "        initial_message = message  # Keep updating until the generator finishes\n",
    "\n",
    "    return initial_message\n",
    "\n",
    "initial_message_content = \"\"\n",
    "\n",
    "def run_langgraph_agent():\n",
    "    \"\"\"Run the LangGraph agent and redirect its stdout.\"\"\"\n",
    "    global initial_message_content\n",
    "    run_car_buyer_agent()  # Start the LangGraph workflow\n",
    "\n",
    "\n",
    "if USE_GRADIO:\n",
    "    # Run the agent in a separate thread\n",
    "    agent_thread = threading.Thread(target=run_langgraph_agent, daemon=True)\n",
    "    agent_thread.start()\n",
    "\n",
    "    initial_message_content = get_initial_message()\n",
    "\n",
    "    initial_messages = [{\"role\": \"assistant\", \"content\": initial_message_content}]\n",
    "\n",
    "    chat = gr.ChatInterface(interact_with_agent,\n",
    "                    chatbot=gr.Chatbot(label=\"Car Buyer Chatbot\", autoscroll=True, scale=1, value=initial_messages, type=\"messages\", height=200),\n",
    "                    type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "start-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
